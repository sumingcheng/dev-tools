services:
  vllm:
    image: ghcr.io/vllm-project/vllm:latest
    restart: always
    ports:
      - '8000:8000'
    volumes:
      - ../models:/models
      - ./logs:/logs
    environment:
      - HUGGING_FACE_HUB_TOKEN=你的HF_TOKEN # 如果需要的话
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command: >
      --model ../models/DeepSeek-R1-Distill-Qwen-7B
      --host 0.0.0.0
      --port 8000
      --tensor-parallel-size 1
      --max-num-seqs 128
      --max-batch-size 32
      --quantization awq
      --trust-remote-code
